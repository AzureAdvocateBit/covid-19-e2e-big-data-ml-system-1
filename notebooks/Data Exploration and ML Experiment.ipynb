{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# reading parquet files from the curated data\ndirPath = '/mnt/root/COVID19_TWEETS/CURATED/'"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# read the data in batch\ntweets = spark.read.parquet(dirPath)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# just to get a feel of how much data we are dealing with:\ntweets.where(tweets['user_location'] =='US').count()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["tweets.where(tweets[\"text\"]=='').count()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["tweets = tweets.where(tweets[\"text\"]!='')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["tweets.where(tweets[\"text\"].isNull()).count()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["tweets.limit(25).toPandas()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["#Leveraging Spark ML:\nData wrangling, feature exctraction and mormalization:"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n\n\n# example of feature exctraction - split text and hash string values\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n\n#build linear regression model - with label col - if the tweet was retweeted or not, this will help us undertand if more people feel the urge to share the message\nlr = LinearRegression(featuresCol= 'features', labelCol='is_retweet')\n\n#Constructe Spark ML pipeline\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\n\nmodel = pipeline.fit(tweets)\n\nprediction = model.transform(tweets)\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["selected = prediction.select(\"text\",\"is_retweet\",\"prediction\")\nfor row in selected.collect():\n    text, ups, prediction = row\n    print(\"(%s) --> is_retweet=%s, prediction=%f\" % (text, str(ups), prediction))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.sql.functions import split\n# clsffity real time data:\n\n# Event Hubs Connection Configuration\nehConf = {\n  'eventhubs.connectionString': dbutils.secrets.get(scope=\"mle2ebigdatakv\", key=\"mirrortweetstreamingkey\") }\n\n\ninput = spark.readStream.format(\"eventhubs\").options(**ehConf).load()\ncasted = input.withColumn(\"body\",input[\"body\"].cast(\"string\"))\ninput_text = casted.withColumn(\"text\",split('body',\",\")[0]).select(\"text\")\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["prediction_stream = model.transform(input_text)\n\nselected = prediction_stream.select(\"text\",\"prediction\")\n\n\nselected.writeStream.outputMode(\"append\").format(\"console\").option(\"truncate\", false).start().awaitTermination()\n\n# we print it to the console to get a feel of the model, if we are happy with the results, we will save it file system \nfor row in selected:\n    text, prediction = row\n    print(\"(%s) --> prediction=%f\" % (text, prediction))\n    \n#for traking the model we use mlflow, read more about it here: https://bit.ly/3jUqHUi\n\n\n\nmodel.write.save(\"/mnt/root/COVID19_TWEETS/ML-Models/V1\")\n"],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"Data Exploration and ML Experiment","notebookId":1689419707369095},"nbformat":4,"nbformat_minor":0}
